<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Text2Image on Mem.Capsule</title>
    <link>https://yuhaoo00.github.io/tags/text2image/</link>
    <description>Recent content in Text2Image on Mem.Capsule</description>
    <image>
      <title>Mem.Capsule</title>
      <url>https://yuhaoo00.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://yuhaoo00.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 26 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://yuhaoo00.github.io/tags/text2image/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Generating Images Like Texts</title>
      <link>https://yuhaoo00.github.io/posts/snapshots/2309arforvisiongeneration/</link>
      <pubDate>Tue, 26 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yuhaoo00.github.io/posts/snapshots/2309arforvisiongeneration/</guid>
      <description>Can we generate images in the same way as autoregressive language model?
Although this sounds simpler than diffusion models, we still need to deal with many computational cost problems. But don&amp;rsquo;t worry too much, there are serval brilliant methods to try to make this idea more competitive.
Taming Transformer -&amp;gt; Patrick Esser, et al. CVPR 2021
The key challenge of autoregressive generation is how to solve the quadratically increasing cost of image sequences that are much longer than texts.</description>
    </item>
    
    <item>
      <title>Two Inpainting Pipelines in Diffusers</title>
      <link>https://yuhaoo00.github.io/posts/analysis/2307inpaintpipeline/</link>
      <pubDate>Thu, 20 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yuhaoo00.github.io/posts/analysis/2307inpaintpipeline/</guid>
      <description>Guided Generation Hybrid-condition by Fine-Tuning </description>
    </item>
    
    <item>
      <title>Network Design in Stable Diffusion</title>
      <link>https://yuhaoo00.github.io/posts/analysis/2306sdnetwork/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yuhaoo00.github.io/posts/analysis/2306sdnetwork/</guid>
      <description>StabilityAI has recently open sourced a series of foundational models for image generation, called Stable Diffusion. Although we know these models are based on latent diffusion, there are few reports mention their detailed designs. To facilitate better understanding and potential future improvement, this blog provide some information about the designs of Unet and VAE, which are key components of the magic generation.
Unet Fig. 1: Overall of the Unet in Stable Diffusion 1.</description>
    </item>
    
  </channel>
</rss>
