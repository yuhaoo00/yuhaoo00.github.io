<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>InverseProblem on Mem.Capsule ðŸ’Š</title>
    <link>https://yuhaoo00.github.io/tags/inverseproblem/</link>
    <description>Recent content in InverseProblem on Mem.Capsule ðŸ’Š</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-GB</language>
    <lastBuildDate>Tue, 20 Dec 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://yuhaoo00.github.io/tags/inverseproblem/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Inverse Problem Ã— Diffusion -- Part: B</title>
      <link>https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinverseb/</link>
      <pubDate>Tue, 20 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinverseb/</guid>
      <description>&lt;h2 id=&#34;ddrm&#34; class=&#34;icon-inline&#34; id=&#34;ddrm&#34;&gt;DDRM&lt;a class=&#34;icon-link&#34; href=&#34;#ddrm&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/2201.11793&#34;&gt;-&amp;gt; Bahjat Kawar, et al. NeurIPS, 2022.&lt;/a&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;img src=&#34;https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231018160625.png&#34; loading=&#34;lazy&#34;&gt;
&lt;figcaption&gt;
Illustration of DDRM (source from paper)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;transformation-via-svd&#34; class=&#34;icon-inline&#34; id=&#34;transformation-via-svd&#34;&gt;Transformation via SVD&lt;a class=&#34;icon-link&#34; href=&#34;#transformation-via-svd&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Similar to &lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2021/hash/b5c01503041b70d41d80e3dbe31bbd8c-Abstract.html&#34;&gt;SNIPS&lt;/a&gt;, DDRM consider the singular value decomposition (SVD) of the sampling matrix $H$ as follows:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
y&amp;amp;=Hx+z\
y&amp;amp;=U\Sigma V^\top x+z\
\Sigma^{â€ } U^{\top}y&amp;amp;=V^\top x+\Sigma^{â€ } U^{\top}z\
\bar{y}&amp;amp;=\bar{x}+\bar{z}\
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Since $U$ is orthogonal matrix, we have $p(U^\top z) = p(z) = \mathcal{N}(0,\sigma^2_y I)$, resulting $\bar{z}^{(i)}=(\Sigma^{â€ } U^{\top}z)^{(i)} \sim \mathcal{N}(0, \frac{\sigma^2_y}{s_i^2}I)$. So after these, we transform $x$ and $y$ into the same field (&lt;strong&gt;spectral space&lt;/strong&gt;), and these two only differ by the noise $\bar{z}$, which can be drawn as follows:&lt;/p&gt;
&lt;p&gt;$$
q(\bar{y}^{(i)}|x_0)=\mathcal{N}(\bar{x}_0^{(i)},\sigma_y^2/s_i^2 )
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;DDRM might be unable to cope with the wild scene, cause the variance $\sigma_y$ is often unknown.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;conditional-diffusion--generation&#34; class=&#34;icon-inline&#34; id=&#34;conditional-diffusion--generation&#34;&gt;Conditional Diffusion &amp;amp; Generation&lt;a class=&#34;icon-link&#34; href=&#34;#conditional-diffusion--generation&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The desired conditional diffusion process should (a) be a tractable Gaussian distribution, (b) employ the known $y$ to construct noisy samples as possible and (c) ensure the original marginal:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
q(x_t|x_0) = q(\bar{x}_t|x_0, y)\cdot q(\bar{y}|x_0)=\mathcal{N}(\bar{x}_0,\sigma_t^2I) \
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;We note that $q(\bar{y}^{(i)}|x_0)=\mathcal{N}(\bar{x}_0^{(i)},\sigma_y^2/s_i^2 )$, so these conditional processes can be defined as follows:
&lt;img src=&#34;https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231018141254.png&#34; alt=&#34;image.png&#34;&gt;
From the perspective of DDIM, we can deduce the corresponding generative process via replacing $x_0$ with &amp;ldquo;the predicted version&amp;rdquo; as follows:
&lt;img src=&#34;https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231018153006.png&#34; alt=&#34;image.png&#34;&gt;
Intuitively, this construction considers different cases for each index of the spectral space. (i) If the corresponding singular value $s_i=0$, then $y$ does not directly provide any information to that index, and the update is similar to regular unconditional generation. (ii) If $s_i &amp;gt;0$, then the updates consider the information provided by $y$, which further depends on whether the measurementsâ€™ noise level $\sigma_y/s_i$ in the spectral space is larger than the noise level in the diffusion model or not.&lt;/p&gt;
&lt;p&gt;In the resulting generation, the initial sample carries a few information from $\bar{y}$, then is updated eventually by the guidance of $p_\theta(\bar{x}_t|x_t+1,y)$,  and is recovered to $x_0$ exactly by left multiplying $V$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Although this conditional process results in a more complex ELBO objective for training, the authors proof that an optimal solution to DDPM / DDIM can also be an optimal solution to a DDRM problem, under some similar assumptions as in DDIM. So &lt;strong&gt;DDRM can be training-free&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;one-more-thing&#34; class=&#34;icon-inline&#34; id=&#34;one-more-thing&#34;&gt;One more thing&lt;a class=&#34;icon-link&#34; href=&#34;#one-more-thing&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;DDRM is applied in super-resolution, deblurring, inpainting, and colorization. There&amp;rsquo;re no much difference of the value space between original $x$ and degraded $y$ in these task. These data are almost all in the perceptible pixel space. So does SVD really work as claimed? This paper lacks relevant ablation study for that. Maybe we should introduce this into more tasks, such as compressive sensing, and see what will happen.&lt;/p&gt;
&lt;h1 id=&#34;references&#34; class=&#34;icon-inline&#34; id=&#34;references&#34;&gt;References&lt;a class=&#34;icon-link&#34; href=&#34;#references&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Kawar, Bahjat, Gregory Vaksman, and Michael Elad. &amp;ldquo;SNIPS: Solving noisy inverse problems stochastically.&amp;rdquo;Â &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt;Â 34 (2021): 21757-21769.&lt;/li&gt;
&lt;li&gt;Kawar, Bahjat, et al. &amp;ldquo;Denoising diffusion restoration models.&amp;rdquo;Â &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt;Â 35 (2022): 23593-23606.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Inverse Problem Ã— Diffusion -- Part: A</title>
      <link>https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinversea/</link>
      <pubDate>Mon, 19 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinversea/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;An inverse problem seeks to recover an unknown signal from a set of observed measurements. Specifically, suppose $x\in R^n$ is an unknown signal, and $y\in R^m = Ax+z$ is a noisy observation given by m linear measurements, where the measurement acquisition process is represented by a linear operator $A\in R^{m\times n}$, and $z\in R^n$ represents a noise vector. Solving a linear inverse problem amounts to recovering the signal $x$ from its measurement $y$. Without further assumptions, the problem is ill-defined when $m&amp;lt; n$, so we additionally assume that $x$ is sampled from a prior distribution $p(x)$&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;source from &lt;a href=&#34;http://arxiv.org/abs/2111.08005&#34;&gt;Dr. Yang Song&amp;rsquo;s paper&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As unconditional generative model, Diffusion models (or Score models) can play a prior term in optimization for various ill-posed image inverse problems. Such methods are often labeled as training-free, zero-shot, unsupervised, etc.&lt;/p&gt;
&lt;p&gt;On the other hand, Diffusion models also can be trained as conditional one $s_\theta(x_t,y,t)$, where $y$ is the condition from other mode. However, this will consume a lot of resources both in the computing power and the collection of paired data $\lbrace x_i,y_i\rbrace$.&lt;/p&gt;
&lt;h2 id=&#34;medical-score-sde&#34; class=&#34;icon-inline&#34; id=&#34;medical-score-sde&#34;&gt;Medical Score-SDE&lt;a class=&#34;icon-link&#34; href=&#34;#medical-score-sde&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/2111.08005&#34;&gt;-&amp;gt; Yang Song, et al. in ICLR, 2022.&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;img src=&#34;https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231017172654.png&#34; loading=&#34;lazy&#34;&gt;
&lt;figcaption&gt;
The medical imaging problem (source from paper)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&#34;step1-perturbing-measurements&#34; class=&#34;icon-inline&#34; id=&#34;step1-perturbing-measurements&#34;&gt;step1: Perturbing measurements&lt;a class=&#34;icon-link&#34; href=&#34;#step1-perturbing-measurements&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Since $x_t=\alpha(t)x_0+\beta(t)z$, and we set $y_t=Ax_t+\alpha(t)\epsilon$, so we have $y_t=\alpha(t)y+\beta(t)Az$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Smart and reasonable assumption for the coefficient $+\alpha(t)\epsilon$ to avoid the subsequent diffusion of random measurement noise $\epsilon$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step2-generation-with-score-sde&#34; class=&#34;icon-inline&#34; id=&#34;step2-generation-with-score-sde&#34;&gt;step2: Generation with Score-SDE&lt;a class=&#34;icon-link&#34; href=&#34;#step2-generation-with-score-sde&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Using the Euler-Maruyama sampler, the generative process given by:&lt;/p&gt;
&lt;p&gt;$$
x_{t-\Delta t} = x_t-f(t)x_t\Delta t+g(t)^2s_\theta(x_t,t)\Delta t+g(t)\sqrt{\Delta t}z
$$&lt;/p&gt;
&lt;p&gt;where $s_\theta(\cdot)$ is the trained score model, $\Delta t = 1/N$ is the set discrete time, and $z\sim \mathcal{N}(0,1)$.&lt;/p&gt;
&lt;h3 id=&#34;step3-consistent-guidance&#34; class=&#34;icon-inline&#34; id=&#34;step3-consistent-guidance&#34;&gt;step3: Consistent Guidance&lt;a class=&#34;icon-link&#34; href=&#34;#step3-consistent-guidance&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;image&#34;&gt;
&lt;img src=&#34;https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231017164345.png&#34; loading=&#34;lazy&#34;&gt;
&lt;figcaption&gt;
The pipeline of medical Score-SDE&lt;/figcaption&gt;
&lt;/figure&gt;

We set the guided intermediate result as $x_t^{\prime}$, For simultaneously minimizing the distance between $x_t$ and $x_t^{\prime}$, and the distance between $x_t^{\prime}$ and the hyperplane $\lbrace x\in R^n| Ax=y_t \rbrace$, we build an  optimization problem as:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
x_t^{\prime}&amp;amp;=\arg \min_{v\in R^n}\lbrace (1-\lambda)\Vert v-x_t \Vert_{T}^2 + \min_{u\in R^n} \lambda \Vert v-u \Vert_{T}^2 \rbrace \
s.t.\quad Au&amp;amp;=y_t
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;which has the closed-form solution as:&lt;/p&gt;
&lt;p&gt;$$
x_t^{\prime}=T^{-1}[\lambda \Lambda \mathcal{P} ^{-1}(\Lambda)y_t+(1-\lambda)\Lambda Tx_t+(1-\Lambda)Tx_t]
$$&lt;/p&gt;
&lt;p&gt;When the measurement process is noisy, we can choose $0&amp;lt;\lambda&amp;lt;1$ to allow slackness in $Ax_t^{\prime}=y_t$ (more affected by $p(x)$). When the measurement process contains no noise, the authors chosse $\lambda=1$ at the last sampling step to guarantee $Ax_0^{\prime}=y$.&lt;/p&gt;
&lt;h2 id=&#34;score-mri&#34; class=&#34;icon-inline&#34; id=&#34;score-mri&#34;&gt;Score-MRI&lt;a class=&#34;icon-link&#34; href=&#34;#score-mri&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1361841522001268&#34;&gt;-&amp;gt; Hyungjin Chung, et al.  Medical Image Analysis, 2022.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Similar to the above, Score-MRI inserts a more simple consistency mapping after every &amp;ldquo;Predictor&amp;rdquo; and &amp;ldquo;Corrector&amp;rdquo; iteration.&lt;/p&gt;
&lt;p&gt;$$
x_i=x_i+\lambda A^\ast(y-Ax_i)=(I-\lambda A^\ast A)x_i+A^\ast y
$$&lt;/p&gt;
&lt;p&gt;where $A^\ast$ denotes the Hermitian adjoint, and $+\lambda A^\ast (y-Ax_i)$ can be viewed as a rectification for minimizing the distance between $y$ and $Ax_i$. In the hybridtype Algorithm 5 (complex domain and multi-coils for MRI), the authors start with $\lambda = 1.0$ in the first iteration, and linearly decrease the value to $\lambda=0.2$ at the last iteration.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/1706.00051&#34;&gt;GANCS&lt;/a&gt; has an similar rectification $(I-\Phi^{â€ }\Phi)x+\Phi^{â€ }y$, where pseudo-inverse $\Phi^{â€ }$ satisfies $\Phi\Phi^{â€ }\Phi=\Phi$, but without the scaling factor $\lambda$.  In this paper, the authors view $(I-\Phi^{â€ }\Phi)x$ as a projection onto the &lt;a href=&#34;https://dx.doi.org/10.1088/1361-6420/aaf14a&#34;&gt;nullspace&lt;/a&gt; of $\Phi$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;img src=&#34;https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231017182641.png&#34; loading=&#34;lazy&#34; width=&#34;500&#34;&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;ddnm&#34; class=&#34;icon-inline&#34; id=&#34;ddnm&#34;&gt;DDNM&lt;a class=&#34;icon-link&#34; href=&#34;#ddnm&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/2212.00490&#34;&gt;-&amp;gt; Yinhuai Wang, et al. in ICLR, 2023.&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;noise-free&#34; class=&#34;icon-inline&#34; id=&#34;noise-free&#34;&gt;Noise-free&lt;a class=&#34;icon-link&#34; href=&#34;#noise-free&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Similar to &lt;a href=&#34;http://arxiv.org/abs/1706.00051&#34;&gt;GANCS&lt;/a&gt;, DDNM adopts a rectified estimation as:&lt;/p&gt;
&lt;p&gt;$$
x_{0|t}^{\prime}=A^{â€ }y+(I-A^{â€ }A)x_{0|t}
$$&lt;/p&gt;
&lt;p&gt;where $x_{0|t}$ is the predicted version at timestep $t$. Based on &lt;a href=&#34;http://arxiv.org/abs/2010.02502&#34;&gt;DDIM&lt;/a&gt;, the generative process can be driven by $x_{t-1}\sim \mathcal{p}(x_{t-1}|x_t,x_{0|t}^{\prime})$. So it might provide a more reliable rectification to human-perceptible $x_{0|t}$, rather than noisy $x_t$ like in &lt;a href=&#34;http://arxiv.org/abs/2010.02502&#34;&gt;Score-MRI&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Although this paper mentioned that this consistency mapping was inspired by &lt;strong&gt;range-null space decomposition&lt;/strong&gt; $x=A^{â€ }Ax+(I-A^{â€ }A)x$, but it seems to contradict with the subsequent DDNM+ for the noisy inverse problem.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;noisy&#34; class=&#34;icon-inline&#34; id=&#34;noisy&#34;&gt;Noisy&lt;a class=&#34;icon-link&#34; href=&#34;#noisy&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;$$
x_{0|t}^{\prime}=A^â€ y+(Iâˆ’A^â€ A)x_{0|t} =x_{0|t}-A^â€ (Ax_{0|t}-y)
$$&lt;/p&gt;
&lt;p&gt;In short, the authors employ two scale factors $\Sigma_t$ &amp;amp; $\Phi_t$ into range-space correction &amp;amp; generative variance, respectively.&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
x_{0|t}^{\prime}&amp;amp;= x_{0|t}-\Sigma_tA^â€ (Ax_{0|t}-y)\\
p^{\prime}(x_{t-1}|x_t,x_{0|t}^{\prime})&amp;amp;=\mathcal{N}(x_{t-1};\mu_t(x_t, x_{0|t}^{\prime}),\Phi_t I)
\end{aligned}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;However, the performance gains from these factor are not clear, due to the absence of ablations experiments. It looks like the &amp;ldquo;Time-Travel&amp;rdquo; (a kind of redundant computing) helped a lot.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&#34;image&#34;&gt;
&lt;img src=&#34;https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231017212649.png&#34; loading=&#34;lazy&#34; width=&#34;300&#34;&gt;
&lt;figcaption&gt;
Time-Travel (source from paper)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h1 id=&#34;references&#34; class=&#34;icon-inline&#34; id=&#34;references&#34;&gt;References&lt;a class=&#34;icon-link&#34; href=&#34;#references&#34; aria-hidden=&#34;true&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;
  &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt;
  &lt;path d=&#34;M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5&#34; /&gt;
  &lt;path d=&#34;M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5&#34; /&gt;
&lt;/svg&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Yang Song and others, â€˜Solving Inverse Problems in Medical Imaging with Score-Based Generative Modelsâ€™  in &lt;em&gt;International Conference on Learning Representations&lt;/em&gt;, 2022.&lt;/li&gt;
&lt;li&gt;Hyungjin Chung and Jong Chul Ye, â€˜Score-Based Diffusion Models for Accelerated MRIâ€™, &lt;em&gt;Medical Image Analysis&lt;/em&gt;, 80 (2022), 102479.&lt;/li&gt;
&lt;li&gt;Johannes Schwab, Stephan Antholzer, and Markus Haltmeier, â€˜Deep Null Space Learning for Inverse Problems: Convergence Analysis and Ratesâ€™, &lt;em&gt;Inverse Problems&lt;/em&gt;, 35.2 (2019), 025008.&lt;/li&gt;
&lt;li&gt;Morteza Mardani and others, â€˜Deep Generative Adversarial Networks for Compressed Sensing Automates MRIâ€™ arXiv, 2017.&lt;/li&gt;
&lt;li&gt;Yinhuai Wang, Jiwen Yu, and Jian Zhang, â€˜Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Modelâ€™ in &lt;em&gt;International Conference on Learning Representations&lt;/em&gt;, 2023.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    </channel>
</rss>
