<!DOCTYPE html>
<html class="nojs" lang="en-GB" dir="ltr">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Yu&#39;s MemoCapsule</title>
<link rel="alternate" type="application/rss+xml" title="rss" href="https://yuhaoo00.github.io/index.xml">
<link rel="alternate" type="application/json" title="json" href="https://yuhaoo00.github.io/index.json">
<meta name="view-transition" content="same-origin">
<meta name="description" content="Encapsulating what I think Hi, this is Yuhao. I‚Äôm documenting my learning notes in this blog as follows. üçø Snapshot: Summarize some interesting papers, easy for ‚Ä¶">
<meta name="created" content="2023-09-26T00:00:00+0000">
<meta name="modified" content="2023-09-26T00:00:00+0000">

<meta name="contact" content="TimberH2000@outlook.com">
<meta property="og:site_name" content="Yu&#39;s MemoCapsule">
<meta property="og:title" content="Encapsulating what I think.">
<meta property="og:url" content="https://yuhaoo00.github.io/">
<meta property="og:type" content="website">
<meta property="og:image" content="https://yuhaoo00.github.io/favicon-192.png">
<meta name="generator" content="Hugo 0.118.2">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="theme-color" content="#ffffff">


<link rel="canonical" href="https://yuhaoo00.github.io/">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

<link rel="stylesheet" href="/css/mobile.928a90a2e5ceccad718844ea67aa6bba151ff555ab514fb103071cc7b60c2ff2.css" media="screen">
<link rel="stylesheet" href="/css/styles.4b0725243fe74b2ef00d4a9effe4e55d8555c705d333dd673a4232e7c4693eac.css">
<link rel="stylesheet" href="/css/print.31e2819287afc91406f2fd43d21a8ba4a0cdfc272e439c90db0c6e47efc7c346.css" media="print">

<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "WebPage",
    "url" : "https://yuhaoo00.github.io/",
    "name": "Encapsulating what I think.",
    "description": "Encapsulating what I think",
    "image" : "https://yuhaoo00.github.io/favicon-192.png",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://yuhaoo00.github.io"
    },
    "publisher": {
      "@type": "Organization",
      "name": "Yu's MemoCapsule",
      "logo" : {
        "@type": "ImageObject",
        "url": "https://yuhaoo00.github.io/favicon-192.png"
      },
      "url": "https://yuhaoo00.github.io"
    }
  }
</script>

<script src="/js/script-early.214cc4b0248ef64425811a906c0c6a3702edffba5dbc127128e9ff989c74c137.js"></script>

<script defer src="/js/mobile.2ee7f57bec29e942a94fc13cd4cf128b0b8daf996652b9725d7e9bf960496721.js"></script>
<script defer src="/js/script.1688e04483adf683d47143ac70e770c7b5e4b75213641f33b46d9b84cb3e91ca.js"></script>




</head>

<body class="list-page front">
<div class="page layout__page">
<header class="header layout__header">
<a href="/" title="Home" rel="home" class="header__logo">
<img src="/images/logo.png" width="40" height="40" alt="Home" class="header__logo-image">
</a>
<h1 class="header__site-name">
<a href="/" title="Home" class="header__site-link" rel="home"><span>Yu&#39;s MemoCapsule</span></a>
</h1>
<div class="region header__region">
</div>
<div class="mobile-nav" dir="ltr">
  <div class="mobile-nav__cover"></div>
  <button class="mobile-nav__toggle button--outline" aria-expanded="false" aria-controls="sheet">
    Menu
    <svg class="mobile-nav__hamburger" viewBox="0 0 100 100" focusable="false" aria-hidden="true">
      <rect width="80" height="12" x="10" y="20" rx="5"></rect>
      <rect width="80" height="12" x="10" y="45" rx="5"></rect>
      <rect width="80" height="12" x="10" y="70" rx="5"></rect>
    </svg>
  </button>
  <div class="mobile-nav__sheet link-inverted link-nav" id="sheet" aria-hidden="true">
    <div class="mobile-nav__region"></div>
    <nav class="mobile-nav__main-menu" aria-label="Main menu">
    <ul class="mobile-nav__navbar">
    <li><a href="/" aria-current="page">Home</a></li>
    <li><a href="/contact/">Contact</a></li>
    <li><a href="/search/">Search</a></li>
    <li><a href="/posts/">Posts</a></li>
    </ul>
    </nav>
  </div>
</div>
</header>

<nav class="main-menu layout__navigation" aria-label="Main menu">
<ul class="navbar">
<li><a href="/" aria-current="page">Home</a></li>
<li><a href="/contact/">Contact</a></li>
<li><a href="/search/">Search</a></li>
<li><a href="/posts/">Posts</a></li>
</ul>
</nav>
<main class="main layout__main">
<h1 id="encapsulating-what-i-think" class="icon-inline" id="encapsulating-what-i-think">Encapsulating what I think<a class="icon-link" href="#encapsulating-what-i-think" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none" />
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg></a></h1>
<p>Hi, this is Yuhao. I‚Äôm documenting my learning notes in this blog as follows.</p>
<ul>
<li>üçø Snapshot: Summarize some interesting papers, easy for retrieval.</li>
<li>üîç Analysis: Dig up overlooked details, especially in engineering.</li>
<li>üí° Idea: Share my solution that might work ü§™.</li>
</ul>


<article class="list-view list-view--posts">
<header>
<h2 class="title mt--s mb--xxs"><a href="/posts/snapshots/2309arforvisiongeneration/">Generating Images Like Texts</a></h2>
<div class="submitted meta">
<time class="created-date" datetime="2023-09-26T00:00:00Z">26 September, 2023</time>

</div>

</header>
<p>Can we generate images in the same way as autoregressive language model?
Although this sounds simpler than diffusion models, we still need to deal with many computational cost problems. But don&rsquo;t worry too much, there are serval brilliant methods to try to make this idea more competitive.
Taming Transformer -&gt; Patrick Esser, et al. CVPR 2021
The key challenge of autoregressive generation is how to solve the quadratically increasing cost of image sequences that are much longer than texts.</p>
</article>

<article class="list-view list-view--posts">
<header>
<h2 class="title mt--s mb--xxs"><a href="/posts/snapshots/2309clip/">Learning the Multi-modal Feature Space</a></h2>
<div class="submitted meta">
<time class="created-date" datetime="2023-09-11T00:00:00Z">11 September, 2023</time>

</div>

</header>
<p>In multi-modal tasks, one of the key challenges is the alignment between feature spaces of different modals. CLIP is representative of this type of work. Although its motivation is to learn a transferable visual model (like BERT) for downstream vision tasks, CLIP has brought a lot of inspirations for multi-modal tasks. Therefore, I prefer to describe CLIP and variants as how to learn a better multi-modal feature space.
CLIP -&gt; Alec Radford, et al.</p>
</article>

<article class="list-view list-view--posts">
<header>
<h2 class="title mt--s mb--xxs"><a href="/posts/snapshots/2308controlgenerationa/">Controllable Text-To-Image Diffusion Models ‚Äî‚Äî Explicit Control</a></h2>
<div class="submitted meta">
<time class="created-date" datetime="2023-08-17T00:00:00Z">17 August, 2023</time>

</div>

</header>
<p>Controllable Text-To-Image (T2I) generation has always been a major challenge in diffusion models. On the one hand, people hope that the generated images can follow some predefined physical attributes, such as the number, position, size, and texture of objects. On the other hand, they also require the T2I models to retain a certain level of creativity.
At present, there are quite a lot of researches related to controllable T2I generation. I prefer to divide them into two categories: one primarily focuses on correcting the generation path in inference, called Explicit Control; the other one strengthens the network through fine-tuning or adding new layers, called Implicit Control.</p>
</article>

<article class="list-view list-view--posts">
<header>
<h2 class="title mt--s mb--xxs"><a href="/posts/analysis/2307inpaintpipeline/">Two Inpainting Pipelines in Diffusers</a></h2>
<div class="submitted meta">
<time class="created-date" datetime="2023-07-20T00:00:00Z">20 July, 2023</time>

</div>

</header>
<p>Guided Generation Hybrid-condition by Fine-Tuning </p>
</article>

<article class="list-view list-view--posts">
<header>
<h2 class="title mt--s mb--xxs"><a href="/posts/analysis/2306sdnetwork/">Network Design in Stable Diffusion</a></h2>
<div class="submitted meta">
<time class="created-date" datetime="2023-02-01T00:00:00Z">1 February, 2023</time>

</div>

</header>
<p>StabilityAI has recently open sourced a series of foundational models for image generation, called Stable Diffusion. Although we know these models are based on latent diffusion, there are few reports mention their detailed designs. To facilitate better understanding and potential future improvement, this blog provide some information about the designs of Unet and VAE, which are key components of the magic generation.
Unet Fig. 1: Overall of the Unet in Stable Diffusion 1.</p>
</article>

<nav class="pager">
<a href="/page/2/" rel="next" class="pager__item pager__item--next">Next<span aria-hidden="true"> ¬ª</span></a>
</nav>

</main>


<footer class="footer layout__footer mt--l">
<p>Follow: <a rel="alternate" type="application/rss&#43;xml" href="https://yuhaoo00.github.io/index.xml">rss</a> | <a rel="alternate" type="application/json" href="https://yuhaoo00.github.io/index.json">json</a></p>
<p><!--Creative Commons License-->This site is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA 4.0</a> licence.<!--/Creative Commons License--></p>


</footer>

</div>
</body>
</html>
