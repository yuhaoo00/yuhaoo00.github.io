<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Inverse Problem × Diffusion -- Part: B | Mem.Capsule</title><meta name=keywords content="Diffusion,ScoreModel,ImageGeneration,InverseProblem,ControlledGeneration"><meta name=description content="DDRM -> Bahjat Kawar, et al. NeurIPS, 2022. Illustration of DDRM (source from paper)
Transformation via SVD Similar to SNIPS, DDRM consider the singular value decomposition (SVD) of the sampling matrix $H$ as follows: $$ \begin{aligned} y&=Hx+z\ y&=U\Sigma V^\top x+z\ \Sigma^{†} U^{\top}y&=V^\top x+\Sigma^{†} U^{\top}z\ \bar{y}&=\bar{x}+\bar{z}\ \end{aligned} $$ Since $U$ is orthogonal matrix, we have $p(U^\top z) = p(z) = \mathcal{N}(0,\sigma^2_y I)$, resulting $\bar{z}^{(i)}=(\Sigma^{†} U^{\top}z)^{(i)} \sim \mathcal{N}(0, \frac{\sigma^2_y}{s_i^2}I)$. So after these, we transform $x$ and $y$ into the same field (spectral space), and these two only differ by the noise $\bar{z}$, which can be drawn as follows: $$ q(\bar{y}^{(i)}|x_0)=\mathcal{N}(\bar{x}_0^{(i)},\sigma_y^2/s_i^2 ) $$"><meta name=author content="Yuhao"><link rel=canonical href=https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinverseb/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.d6c0e4385959ef5b32dbacc9d5c583ce22e75d9b61896b9fa8c1d6e4c98fbde8.css integrity="sha256-1sDkOFlZ71sy26zJ1cWDziLnXZthiWufqMHW5MmPveg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yuhaoo00.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://yuhaoo00.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://yuhaoo00.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://yuhaoo00.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://yuhaoo00.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],output:"htmlAndMathml",strict:!1})})</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Inverse Problem × Diffusion -- Part: B"><meta property="og:description" content="DDRM -> Bahjat Kawar, et al. NeurIPS, 2022. Illustration of DDRM (source from paper)
Transformation via SVD Similar to SNIPS, DDRM consider the singular value decomposition (SVD) of the sampling matrix $H$ as follows: $$ \begin{aligned} y&=Hx+z\ y&=U\Sigma V^\top x+z\ \Sigma^{†} U^{\top}y&=V^\top x+\Sigma^{†} U^{\top}z\ \bar{y}&=\bar{x}+\bar{z}\ \end{aligned} $$ Since $U$ is orthogonal matrix, we have $p(U^\top z) = p(z) = \mathcal{N}(0,\sigma^2_y I)$, resulting $\bar{z}^{(i)}=(\Sigma^{†} U^{\top}z)^{(i)} \sim \mathcal{N}(0, \frac{\sigma^2_y}{s_i^2}I)$. So after these, we transform $x$ and $y$ into the same field (spectral space), and these two only differ by the noise $\bar{z}$, which can be drawn as follows: $$ q(\bar{y}^{(i)}|x_0)=\mathcal{N}(\bar{x}_0^{(i)},\sigma_y^2/s_i^2 ) $$"><meta property="og:type" content="article"><meta property="og:url" content="https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinverseb/"><meta property="og:image" content="https://yuhaoo00.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-20T00:00:00+00:00"><meta property="article:modified_time" content="2022-12-20T00:00:00+00:00"><meta property="og:site_name" content="Mem.Capsule"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yuhaoo00.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Inverse Problem × Diffusion -- Part: B"><meta name=twitter:description content="DDRM -> Bahjat Kawar, et al. NeurIPS, 2022. Illustration of DDRM (source from paper)
Transformation via SVD Similar to SNIPS, DDRM consider the singular value decomposition (SVD) of the sampling matrix $H$ as follows: $$ \begin{aligned} y&=Hx+z\ y&=U\Sigma V^\top x+z\ \Sigma^{†} U^{\top}y&=V^\top x+\Sigma^{†} U^{\top}z\ \bar{y}&=\bar{x}+\bar{z}\ \end{aligned} $$ Since $U$ is orthogonal matrix, we have $p(U^\top z) = p(z) = \mathcal{N}(0,\sigma^2_y I)$, resulting $\bar{z}^{(i)}=(\Sigma^{†} U^{\top}z)^{(i)} \sim \mathcal{N}(0, \frac{\sigma^2_y}{s_i^2}I)$. So after these, we transform $x$ and $y$ into the same field (spectral space), and these two only differ by the noise $\bar{z}$, which can be drawn as follows: $$ q(\bar{y}^{(i)}|x_0)=\mathcal{N}(\bar{x}_0^{(i)},\sigma_y^2/s_i^2 ) $$"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://yuhaoo00.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Inverse Problem × Diffusion -- Part: B","item":"https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinverseb/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Inverse Problem × Diffusion -- Part: B","name":"Inverse Problem × Diffusion -- Part: B","description":"DDRM -\u0026gt; Bahjat Kawar, et al. NeurIPS, 2022. Illustration of DDRM (source from paper)\nTransformation via SVD Similar to SNIPS, DDRM consider the singular value decomposition (SVD) of the sampling matrix $H$ as follows: $$ \\begin{aligned} y\u0026amp;=Hx+z\\ y\u0026amp;=U\\Sigma V^\\top x+z\\ \\Sigma^{†} U^{\\top}y\u0026amp;=V^\\top x+\\Sigma^{†} U^{\\top}z\\ \\bar{y}\u0026amp;=\\bar{x}+\\bar{z}\\ \\end{aligned} $$ Since $U$ is orthogonal matrix, we have $p(U^\\top z) = p(z) = \\mathcal{N}(0,\\sigma^2_y I)$, resulting $\\bar{z}^{(i)}=(\\Sigma^{†} U^{\\top}z)^{(i)} \\sim \\mathcal{N}(0, \\frac{\\sigma^2_y}{s_i^2}I)$. So after these, we transform $x$ and $y$ into the same field (spectral space), and these two only differ by the noise $\\bar{z}$, which can be drawn as follows: $$ q(\\bar{y}^{(i)}|x_0)=\\mathcal{N}(\\bar{x}_0^{(i)},\\sigma_y^2/s_i^2 ) $$","keywords":["Diffusion","ScoreModel","ImageGeneration","InverseProblem","ControlledGeneration"],"articleBody":"DDRM -\u003e Bahjat Kawar, et al. NeurIPS, 2022. Illustration of DDRM (source from paper)\nTransformation via SVD Similar to SNIPS, DDRM consider the singular value decomposition (SVD) of the sampling matrix $H$ as follows: $$ \\begin{aligned} y\u0026=Hx+z\\ y\u0026=U\\Sigma V^\\top x+z\\ \\Sigma^{†} U^{\\top}y\u0026=V^\\top x+\\Sigma^{†} U^{\\top}z\\ \\bar{y}\u0026=\\bar{x}+\\bar{z}\\ \\end{aligned} $$ Since $U$ is orthogonal matrix, we have $p(U^\\top z) = p(z) = \\mathcal{N}(0,\\sigma^2_y I)$, resulting $\\bar{z}^{(i)}=(\\Sigma^{†} U^{\\top}z)^{(i)} \\sim \\mathcal{N}(0, \\frac{\\sigma^2_y}{s_i^2}I)$. So after these, we transform $x$ and $y$ into the same field (spectral space), and these two only differ by the noise $\\bar{z}$, which can be drawn as follows: $$ q(\\bar{y}^{(i)}|x_0)=\\mathcal{N}(\\bar{x}_0^{(i)},\\sigma_y^2/s_i^2 ) $$\nDDRM might be unable to cope with the wild scene, cause the variance $\\sigma_y$ is often unknown.\nConditional Diffusion \u0026 Generation The desired conditional diffusion process should (a) be a tractable Gaussian distribution, (b) employ the known $y$ to construct noisy samples as possible and (c) ensure the original marginal: $$ \\begin{aligned} q(x_t|x_0) = q(\\bar{x}_t|x_0, y)\\cdot q(\\bar{y}|x_0)=\\mathcal{N}(\\bar{x}_0,\\sigma_t^2I) \\ \\end{aligned} $$ We note that $q(\\bar{y}^{(i)}|x_0)=\\mathcal{N}(\\bar{x}_0^{(i)},\\sigma_y^2/s_i^2 )$, so these conditional processes can be defined as follows: From the perspective of DDIM, we can deduce the corresponding generative process via replacing $x_0$ with “the predicted version” as follows: Intuitively, this construction considers different cases for each index of the spectral space. (i) If the corresponding singular value $s_i=0$, then $y$ does not directly provide any information to that index, and the update is similar to regular unconditional generation. (ii) If $s_i \u003e0$, then the updates consider the information provided by $y$, which further depends on whether the measurements’ noise level $\\sigma_y/s_i$ in the spectral space is larger than the noise level in the diffusion model or not.\nIn the resulting generation, the initial sample carries a few information from $\\bar{y}$, then is updated eventually by the guidance of $p_\\theta(\\bar{x}_t|x_t+1,y)$, and is recovered to $x_0$ exactly by left multiplying $V$.\nAlthough this conditional process results in a more complex ELBO objective for training, the authors proof that an optimal solution to DDPM / DDIM can also be an optimal solution to a DDRM problem, under some similar assumptions as in DDIM. So DDRM can be training-free.\nOne more thing DDRM is applied in super-resolution, deblurring, inpainting, and colorization. There’re no much difference of the value space between original $x$ and degraded $y$ in these task. These data are almost all in the perceptible pixel space. So does SVD really work as claimed? This paper lacks relevant ablation study for that. Maybe we should introduce this into more tasks, such as compressive sensing, and see what will happen.\nReferences Kawar, Bahjat, Gregory Vaksman, and Michael Elad. “SNIPS: Solving noisy inverse problems stochastically.” Advances in Neural Information Processing Systems 34 (2021): 21757-21769. Kawar, Bahjat, et al. “Denoising diffusion restoration models.” Advances in Neural Information Processing Systems 35 (2022): 23593-23606. ","wordCount":"463","inLanguage":"en","datePublished":"2022-12-20T00:00:00Z","dateModified":"2022-12-20T00:00:00Z","author":{"@type":"Person","name":"Yuhao"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinverseb/"},"publisher":{"@type":"Organization","name":"Mem.Capsule","logo":{"@type":"ImageObject","url":"https://yuhaoo00.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yuhaoo00.github.io accesskey=h title="Mem.Capsule (Alt + H)"><img src=https://yuhaoo00.github.io/apple-touch-icon.png alt aria-label=logo height=35>Mem.Capsule</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://yuhaoo00.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://yuhaoo00.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://yuhaoo00.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://yuhaoo00.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Inverse Problem × Diffusion -- Part: B</h1><div class=post-meta><span title='2022-12-20 00:00:00 +0000 UTC'>December 20, 2022</span>&nbsp;·&nbsp;463 words&nbsp;·&nbsp;Yuhao</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#ddrm>DDRM</a><ul><li><a href=#transformation-via-svd>Transformation via SVD</a></li><li><a href=#conditional-diffusion--generation>Conditional Diffusion & Generation</a></li><li><a href=#one-more-thing>One more thing</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=ddrm>DDRM<a hidden class=anchor aria-hidden=true href=#ddrm>#</a></h2><p><a href=http://arxiv.org/abs/2201.11793>-> Bahjat Kawar, et al. NeurIPS, 2022.</a><figure class=align-center><img loading=lazy src=https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231018160625.png#center alt="Illustration of DDRM (source from paper)"><figcaption><p>Illustration of DDRM (source from paper)</p></figcaption></figure></p><h3 id=transformation-via-svd>Transformation via SVD<a hidden class=anchor aria-hidden=true href=#transformation-via-svd>#</a></h3><p>Similar to <a href=https://proceedings.neurips.cc/paper_files/paper/2021/hash/b5c01503041b70d41d80e3dbe31bbd8c-Abstract.html>SNIPS</a>, DDRM consider the singular value decomposition (SVD) of the sampling matrix $H$ as follows:
$$
\begin{aligned}
y&=Hx+z\
y&=U\Sigma V^\top x+z\
\Sigma^{†} U^{\top}y&=V^\top x+\Sigma^{†} U^{\top}z\
\bar{y}&=\bar{x}+\bar{z}\
\end{aligned}
$$
Since $U$ is orthogonal matrix, we have $p(U^\top z) = p(z) = \mathcal{N}(0,\sigma^2_y I)$, resulting $\bar{z}^{(i)}=(\Sigma^{†} U^{\top}z)^{(i)} \sim \mathcal{N}(0, \frac{\sigma^2_y}{s_i^2}I)$. So after these, we transform $x$ and $y$ into the same field (<strong>spectral space</strong>), and these two only differ by the noise $\bar{z}$, which can be drawn as follows:
$$
q(\bar{y}^{(i)}|x_0)=\mathcal{N}(\bar{x}_0^{(i)},\sigma_y^2/s_i^2 )
$$</p><blockquote><p>DDRM might be unable to cope with the wild scene, cause the variance $\sigma_y$ is often unknown.</p></blockquote><h3 id=conditional-diffusion--generation>Conditional Diffusion & Generation<a hidden class=anchor aria-hidden=true href=#conditional-diffusion--generation>#</a></h3><p>The desired conditional diffusion process should (a) be a tractable Gaussian distribution, (b) employ the known $y$ to construct noisy samples as possible and (c) ensure the original marginal:
$$
\begin{aligned}
q(x_t|x_0) = q(\bar{x}_t|x_0, y)\cdot q(\bar{y}|x_0)=\mathcal{N}(\bar{x}_0,\sigma_t^2I) \
\end{aligned}
$$
We note that $q(\bar{y}^{(i)}|x_0)=\mathcal{N}(\bar{x}_0^{(i)},\sigma_y^2/s_i^2 )$, so these conditional processes can be defined as follows:
<img loading=lazy src=https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231018141254.png alt=image.png>
From the perspective of DDIM, we can deduce the corresponding generative process via replacing $x_0$ with &ldquo;the predicted version&rdquo; as follows:
<img loading=lazy src=https://image-1300968464.cos.ap-shanghai.myqcloud.com/Obsidian/20231018153006.png alt=image.png>
Intuitively, this construction considers different cases for each index of the spectral space. (i) If the corresponding singular value $s_i=0$, then $y$ does not directly provide any information to that index, and the update is similar to regular unconditional generation. (ii) If $s_i >0$, then the updates consider the information provided by $y$, which further depends on whether the measurements’ noise level $\sigma_y/s_i$ in the spectral space is larger than the noise level in the diffusion model or not.</p><p>In the resulting generation, the initial sample carries a few information from $\bar{y}$, then is updated eventually by the guidance of $p_\theta(\bar{x}_t|x_t+1,y)$, and is recovered to $x_0$ exactly by left multiplying $V$.</p><blockquote><p>Although this conditional process results in a more complex ELBO objective for training, the authors proof that an optimal solution to DDPM / DDIM can also be an optimal solution to a DDRM problem, under some similar assumptions as in DDIM. So <strong>DDRM can be training-free</strong>.</p></blockquote><h3 id=one-more-thing>One more thing<a hidden class=anchor aria-hidden=true href=#one-more-thing>#</a></h3><p>DDRM is applied in super-resolution, deblurring, inpainting, and colorization. There&rsquo;re no much difference of the value space between original $x$ and degraded $y$ in these task. These data are almost all in the perceptible pixel space. So does SVD really work as claimed? This paper lacks relevant ablation study for that. Maybe we should introduce this into more tasks, such as compressive sensing, and see what will happen.</p><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><ul><li>Kawar, Bahjat, Gregory Vaksman, and Michael Elad. &ldquo;SNIPS: Solving noisy inverse problems stochastically.&rdquo; <em>Advances in Neural Information Processing Systems</em> 34 (2021): 21757-21769.</li><li>Kawar, Bahjat, et al. &ldquo;Denoising diffusion restoration models.&rdquo; <em>Advances in Neural Information Processing Systems</em> 35 (2022): 23593-23606.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://yuhaoo00.github.io/tags/diffusion/>Diffusion</a></li><li><a href=https://yuhaoo00.github.io/tags/scoremodel/>ScoreModel</a></li><li><a href=https://yuhaoo00.github.io/tags/imagegeneration/>ImageGeneration</a></li><li><a href=https://yuhaoo00.github.io/tags/inverseproblem/>InverseProblem</a></li><li><a href=https://yuhaoo00.github.io/tags/controlledgeneration/>ControlledGeneration</a></li></ul><nav class=paginav><a class=prev href=https://yuhaoo00.github.io/posts/analysis/2306sdnetwork/><span class=title>« Prev</span><br><span>Network Design in Stable Diffusion</span></a>
<a class=next href=https://yuhaoo00.github.io/posts/snapshots/2212diffusionforinversea/><span class=title>Next »</span><br><span>Inverse Problem × Diffusion -- Part: A</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://yuhaoo00.github.io>Mem.Capsule</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>